import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import PlotFunctions as PF
import sklearn.metrics as metrics
from torch.utils.data import DataLoader, Dataset
from torch.autograd import Variable

from sklearn.model_selection import train_test_split

#Define Net class
class Net(nn.Module):
	def __init__(self):
		super(Net, self).__init__()
		self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)     #60*60
		self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)     #Previous 2*2 pooling => 26*26
		self.nr_flat_features = 16 * 13 * 13                                      #Previous 2x2 pooling => 13x13
		self.fc1 = nn.Linear(self.nr_flat_features, 200)
		self.fc2 = nn.Linear(200, 120)
		self.fc3 = nn.Linear(120, 10)
		
		
	def forward(self, x):
		out = F.max_pool2d(F.relu(self.conv1(x)),2)     #30*30
		out = F.max_pool2d(F.relu(self.conv2(out)),2)   #26*26
		out = out.view(-1,self.nr_flat_features)        #Reshape into vector of (nr_channels=16, 13*13)
		out = self.fc3(F.relu(self.fc2(F.relu(self.fc1(out)))))
		return out

	
#A class to prepare our data for the DataLoader can be defined
'''Any custom dataset class has to inherit from the PyTorch dataset Class.
Also, should have __len__ and __getitem__ atributes
set. __init__ method allows to manipulate and transform our raw data'''
class prepData(Dataset):
	def __init__(self, X, Y):
		X = X.reshape((-1,1,64,64))     #Add one channel to use convolution. first dimensions refers to number of images
		y_order = np.argsort([9,0,7,6,1,8,4,3,2,5])
		Y = Y[:,y_order].argmax(axis=1)            #Y is one hot encoded, thus needs to be converted to integer
		self.X = torch.from_numpy(X)
		self.Y = torch.from_numpy(Y)
		
	def __len__(self):
		#Length of our data
		return len(self.Y)

	def __getitem__(self, idx):
		#Allows to get a sample from our dataset
		X = self.X[idx]
		Y = self.Y[idx]
		
		sample = {'X': X, 'Y': Y}
		return sample

#Load the data and split it in train and test
x_l = np.load('Data\X.npy')
y_l = np.load('Data\Y.npy')
x_train, x_test, y_train, y_test = train_test_split(x_l, y_l, test_size=0.2, random_state=42)

#Transform our data into tensors to be read by our CNN and split it in shuffled batches
batch_size = 32
trainData = prepData(x_train, y_train)
trainDataL = DataLoader(trainData, batch_size=batch_size)

testData = prepData(x_test, y_test)
testDataL = DataLoader(testData, batch_size=batch_size)

net = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters(), lr=0.001)

#Initialize counters for accuracy and epoch
acc_tr, loss_tr = [[],[]],[[],[]]
start_epoch = 0



#Define procedure for training the network
def train(epoch):
	net.train()
	train_loss = 0
	acc_meas = [0,0]
	b_id = 0
	total_sample, total_predictions = [], []
	
	#for each batch generated by DataLoader
	for batch_id, sample in enumerate(trainDataL):
		optimizer.zero_grad()                       #Clear the gradients from our optimizer
		# inputs, targets = sample['X'], sample['Y']
		outputs = net(sample['X'])
		loss = criterion(outputs, sample['Y'])       #Calculate the loss between predictions and targets
		loss.backward()                             #Get the gradient values
		optimizer.step()                            #Update the weights of the optimizer with the gradients calculated
		
		train_loss += loss.item()                   #add the loss of each batch to be able to calculate the overall loss
		_, predicted = torch.max(outputs.data, 1)
		
		total_sample += sample['Y'].tolist()
		total_predictions += predicted.tolist()
		
		acc_meas[1] += sample['Y'].size(0)
		acc_meas[0] += metrics.accuracy_score(sample['Y'], predicted, normalize=False)
		b_id += 1
	
	acc_tr[0].append(100. * acc_meas[0] / acc_meas[1])
	loss_tr[0].append(train_loss/(b_id))
	print('TRAIN Epoch %d | Loss: %.3f | Acc: %.3f%% (%d/%d)' % (
		epoch, train_loss / (b_id), 100. * acc_meas[0] / acc_meas[1], acc_meas[0], acc_meas[1]))
	if epoch == 14:
		print(metrics.classification_report(total_sample, total_predictions))


def test(epoch):
	net.eval()
	test_loss = 0
	acc_meas = [0, 0, 0]
	b_id = 0
	
	# for each batch generated by DataLoader
	for batch_id, sample in enumerate(testDataL):
		outputs = net(sample['X'])
		loss = criterion(outputs, sample['Y']) # Calculate the loss between predictions and targets
		
		test_loss += loss.item()  # add the loss of each batch to be able to calculate the overall loss
		_, predicted = torch.max(outputs.data, 1)
		acc_meas[1] += sample['Y'].size(0)
		acc_meas[0] += metrics.accuracy_score(sample['Y'], predicted, normalize=False)
		b_id += 1
	
	acc_tr[1].append(100. * acc_meas[0] / acc_meas[1])
	loss_tr[1].append(test_loss/(b_id))
	print('TEST  Epoch %d | Loss: %.3f | Acc: %.3f%% (%d/%d)' % (
		epoch, test_loss / (b_id), 100. * acc_meas[0] / acc_meas[1], acc_meas[0], acc_meas[1]))




nr_epochs=15
for epoch in range(start_epoch, start_epoch+nr_epochs):
	train(epoch)
	test(epoch)
	
t = np.arange(nr_epochs)

'''
#Plot accuracy and loss for train and test sets for each epoch
fig, axes = plt.subplots(2,1)
ax1, ax2 = PF.two_y_axis(t,acc_tr[0],loss_tr[0], axes[0])
ax3, ax4 = PF.two_y_axis(t,acc_tr[1],loss_tr[1], axes[1])

#Set axes and colors
ax1.set_ylabel('Accuracy', color='b')
ax1.tick_params('y', colors='b')
ax1.set_title('Accuracy and Loss for Train Set')
ax2.set_ylabel('Loss', color='r')
ax2.tick_params('y', colors='r')

PF.setattrs(ax1.lines[0],'b')
PF.setattrs(ax2.lines[0],'r')

ax3.set_title('Accuracy and Loss for Test Set')
ax3.set_xlabel('Epoch')
ax3.set_ylabel('Accuracy', color='b')
ax3.tick_params('y', colors='b')
ax4.set_ylabel('Loss', color='r')
ax4.tick_params('y', colors='r')

PF.setattrs(ax3.lines[0],'b')
PF.setattrs(ax4.lines[0],'r')
'''

#Plot accuracy
fig, ax = plt.subplots()
plt.plot(t,acc_tr[0],'b-')
plt.plot(t,acc_tr[1],'r-.')
plt.title('Accuracy for Train and Test Sets')
ax.set_xlabel('Epoch')
ax.set_ylabel('Accuracy (%)')

labels = ['train', 'test']
plt.legend(labels, fancybox=True, shadow=True, labelspacing=0.0)

fig.tight_layout()
plt.show()
